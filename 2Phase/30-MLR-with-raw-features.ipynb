{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Multiple-Linear-Regression---Raw-Features\" data-toc-modified-id=\"Multiple-Linear-Regression---Raw-Features-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Multiple Linear Regression - Raw Features</a></span><ul class=\"toc-item\"><li><span><a href=\"#Objectives\" data-toc-modified-id=\"Objectives-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Objectives</a></span></li><li><span><a href=\"#Regression-with-Multiple-Predictors\" data-toc-modified-id=\"Regression-with-Multiple-Predictors-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Regression with Multiple Predictors</a></span></li><li><span><a href=\"#Expanding-Simple-Linear-Regression\" data-toc-modified-id=\"Expanding-Simple-Linear-Regression-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Expanding Simple Linear Regression</a></span></li><li><span><a href=\"#Closed-form-Solution\" data-toc-modified-id=\"Closed-form-Solution-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Closed-form Solution</a></span></li><li><span><a href=\"#Confounding-Variables\" data-toc-modified-id=\"Confounding-Variables-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Confounding Variables</a></span></li><li><span><a href=\"#Multiple-Regression-in-statsmodels\" data-toc-modified-id=\"Multiple-Regression-in-statsmodels-1.6\"><span class=\"toc-item-num\">1.6&nbsp;&nbsp;</span>Multiple Regression in <code>statsmodels</code></a></span><ul class=\"toc-item\"><li><span><a href=\"#Exercise\" data-toc-modified-id=\"Exercise-1.6.1\"><span class=\"toc-item-num\">1.6.1&nbsp;&nbsp;</span>Exercise</a></span></li><li><span><a href=\"#Diamonds-Dataset\" data-toc-modified-id=\"Diamonds-Dataset-1.6.2\"><span class=\"toc-item-num\">1.6.2&nbsp;&nbsp;</span>Diamonds Dataset</a></span></li></ul></li><li><span><a href=\"#Wine-Dataset-üç∑\" data-toc-modified-id=\"Wine-Dataset-üç∑-1.7\"><span class=\"toc-item-num\">1.7&nbsp;&nbsp;</span>Wine Dataset üç∑</a></span><ul class=\"toc-item\"><li><span><a href=\"#üß†-Knowledge-Check\" data-toc-modified-id=\"üß†-Knowledge-Check-1.7.1\"><span class=\"toc-item-num\">1.7.1&nbsp;&nbsp;</span>üß† <strong>Knowledge Check</strong></a></span></li></ul></li><li><span><a href=\"#Running-the-Regression\" data-toc-modified-id=\"Running-the-Regression-1.8\"><span class=\"toc-item-num\">1.8&nbsp;&nbsp;</span>Running the Regression</a></span><ul class=\"toc-item\"><li><span><a href=\"#Adding-an-Intercept-(&quot;Bias&quot;,-&quot;Constant&quot;)-Term\" data-toc-modified-id=\"Adding-an-Intercept-(&quot;Bias&quot;,-&quot;Constant&quot;)-Term-1.8.1\"><span class=\"toc-item-num\">1.8.1&nbsp;&nbsp;</span>Adding an Intercept (\"Bias\", \"Constant\") Term</a></span></li></ul></li></ul></li><li><span><a href=\"#Scaling---The-Missing-&amp;-Helpful-Step\" data-toc-modified-id=\"Scaling---The-Missing-&amp;-Helpful-Step-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Scaling - The Missing &amp; Helpful Step</a></span><ul class=\"toc-item\"><li><span><a href=\"#What's-Going-on-Here?\" data-toc-modified-id=\"What's-Going-on-Here?-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>What's Going on Here?</a></span></li><li><span><a href=\"#A-Solution:-Standard-Scaling\" data-toc-modified-id=\"A-Solution:-Standard-Scaling-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>A Solution: Standard Scaling</a></span><ul class=\"toc-item\"><li><span><a href=\"#Interpretation-of-Coefficients\" data-toc-modified-id=\"Interpretation-of-Coefficients-2.2.1\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>Interpretation of Coefficients</a></span></li></ul></li><li><span><a href=\"#Redoing-with-Standard-Scaling\" data-toc-modified-id=\"Redoing-with-Standard-Scaling-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Redoing with Standard Scaling</a></span><ul class=\"toc-item\"><li><span><a href=\"#üß†-Knowledge-Check\" data-toc-modified-id=\"üß†-Knowledge-Check-2.3.1\"><span class=\"toc-item-num\">2.3.1&nbsp;&nbsp;</span>üß† <strong>Knowledge Check</strong></a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Multiple Linear Regression - Raw Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T17:02:49.771258Z",
     "start_time": "2022-12-01T17:02:47.845227Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import sklearn.metrics as metrics\n",
    "from random import gauss\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy import stats as stats\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "![mlr](https://miro.medium.com/max/1280/1*lJKFo3yyZaFIx4ET1dLmlg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Conduct multiple linear regressions in `statsmodels`\n",
    "- Use standard scaling for linear regression for better interpretation\n",
    "- Conduct linear regressions in `sklearn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Regression with Multiple Predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> It's all a bunch of dials\n",
    "\n",
    "<img width='450px' src='images/dials.png'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The main idea here is pretty simple. Whereas, in simple linear regression we took our dependent variable to be a function only of a single independent variable, here we'll be taking the dependent variable to be a function of multiple independent variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Expanding Simple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Our regression equation, then, instead of looking like $\\hat{y} = mx + b$, will now look like:\n",
    "\n",
    "$\\hat{y} = \\hat{\\beta}_0 + \\hat{\\beta}_1x_1 + ... + \\hat{\\beta}_nx_n$.\n",
    "\n",
    "Remember that the hats ( $\\hat{}$ ) indicate parameters that are estimated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Is this still a best-fit *line*? Well, no. What does the graph of, say, z = x + y look like? [Here's](https://academo.org/demos/3d-surface-plotter/) a 3d-plotter. (Of course, once we get x's with subscripts beyond 2 it's going to be very hard to visualize. But in practice linear regressions can make use of dozens or even of hundreds of independent variables!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Closed-form Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Is it possible to calculate the betas by hand? Yes, a multiple regression problem still has a closed-form solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In a word, for a multiple linear regression problem where $X$ is the matrix of independent variable values and $y$ is the vector of dependent variable values, the vector of optimizing regression coefficients $\\vec{b}$ is given by:\n",
    "\n",
    "$\\vec{b} = (X^TX)^{-1}X^Ty$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We'll focus more directly on matrix mathematics later in the course, so don't worry if this equation is opaque to you. See [here](https://stattrek.com/multiple-regression/regression-coefficients.aspx) for a nice explanation and example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Confounding Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Suppose I have a simple linear regression that models the growth of corn plants as a function of the temperature of the ambient air. And suppose there is a noticeable positive correlation between temperature and plant height."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T17:02:49.802233Z",
     "start_time": "2022-12-01T17:02:49.772226Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "corn = pd.read_csv('data/corn.csv',\n",
    "                  usecols=['temp', 'humid', 'height'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T17:02:50.406726Z",
     "start_time": "2022-12-01T17:02:49.803726Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sns.lmplot(data=corn, x='temp', y='height')\n",
    "plt.xlabel('Temperature ($\\degree$ F)')\n",
    "plt.ylabel('Height (cm)')\n",
    "plt.title('Corn plant height as a function of temperature');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T17:02:50.422258Z",
     "start_time": "2022-12-01T17:02:50.408225Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "corn.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "It seems that higher temperatures lead to taller corn plants. But it's hard to know for sure. One **confounding variable** might be *humidity*. If we haven't controlled for humidity, then it's difficult to draw conclusions.\n",
    "\n",
    "One solution is to use **both features** in a single model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T17:02:50.701224Z",
     "start_time": "2022-12-01T17:02:50.423225Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sns.lmplot(data=corn, x='humid', y='height')\n",
    "plt.xlabel('Humidity (%)')\n",
    "plt.ylabel('Height (cm)')\n",
    "plt.title('Corn plant height as a function of humidity');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T17:02:51.166225Z",
     "start_time": "2022-12-01T17:02:50.702724Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ax = plt.figure(figsize=(8, 6)).add_subplot(111, projection='3d')\n",
    "ax.scatter(corn['temp'], corn['humid'], corn['height'],\n",
    "           depthshade=True, s=40, color='#ff0000')\n",
    "# create x,y\n",
    "xx, yy = np.meshgrid(corn['temp'], corn['humid'])\n",
    "\n",
    "# calculate corresponding z\n",
    "z = 4.3825 * xx + 2.4693 * yy - 255.5434\n",
    "\n",
    "# plot the surface\n",
    "ax.plot_surface(xx, yy, z, alpha=0.01, color='#00ff00')\n",
    "\n",
    "ax.view_init(30, azim=240)\n",
    "ax.set_xlabel('Temperature ($\\degree$ F)')\n",
    "ax.set_ylabel('Humidity (%)')\n",
    "ax.set_zlabel('Height (cm)')\n",
    "plt.title('Corn plant height as a function of temperature and humidity');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "One risk we run when adding more predictors to a model is that their correlations with the target may be nearly *collinear* with each other. This can make it difficult to determine which predictor is doing the heavy lifting. We shall explore this theme of **multicollinearity** in more depth in due course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Multiple Regression in `statsmodels`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's build a multiple regression with `statsmodels`. Let's start with a toy model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T17:02:51.181725Z",
     "start_time": "2022-12-01T17:02:51.168249Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "centers = np.arange(1, 6)\n",
    "preds = np.array([stats.norm(loc=center, scale=3).rvs(200) for center in centers]).T\n",
    "preds_df = pd.DataFrame(preds, columns=[f'var{center}' for center in centers])\n",
    "\n",
    "# Here we're setting the target _exactly_ equal to var1 + 2*var2 + 3*var3 + 4*var4 + 5*var5\n",
    "target = preds_df['var1'] + 2*preds_df['var2'] + 3*preds_df['var3']\\\n",
    "    + 4*preds_df['var4'] + 5*preds_df['var5']\n",
    "target_df = pd.DataFrame(target, columns=['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T17:02:51.197225Z",
     "start_time": "2022-12-01T17:02:51.184225Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.concat([preds_df, target_df], axis=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Use `statsmodels.OLS()` to fit a linear regression model with five input variables to the target.\n",
    "- Run the model summary. What are the betas? What value of $R^2$ did you get?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<details>\n",
    "    <summary>Answer</summary>\n",
    "<code>X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "model = sm.OLS(endog=y, exog=X).fit()\n",
    "model.summary()</code>\n",
    "    </details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Diamonds Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T17:02:51.274225Z",
     "start_time": "2022-12-01T17:02:51.199725Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = sns.load_dataset('diamonds').drop(['cut', 'color', 'clarity'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T17:02:51.289727Z",
     "start_time": "2022-12-01T17:02:51.275726Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T17:02:51.305225Z",
     "start_time": "2022-12-01T17:02:51.291226Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X, y = data.drop('price', axis=1), data['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T17:02:51.351725Z",
     "start_time": "2022-12-01T17:02:51.307225Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model2 = sm.OLS(y, X).fit()\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<details>\n",
    "    <summary><b>Remember that $R^2$ can be negative!</b> Click here for code that demonstrates this.</summary>\n",
    "\n",
    "<code>bad_pred = np.mean(y) * np.ones(len(y))\n",
    "worse_pred = (np.mean(y) + 1000) * np.ones(len(y))\n",
    "print(metrics.r2_score(y, bad_pred))\n",
    "print(metrics.r2_score(y, worse_pred))</code>\n",
    "    </details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Wine Dataset üç∑"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This dataset includes measurable attributes of different wines as well as their rated quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T17:02:51.398225Z",
     "start_time": "2022-12-01T17:02:51.353225Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "wine = pd.read_csv('data/wine.csv')\n",
    "\n",
    "wine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T17:02:51.413725Z",
     "start_time": "2022-12-01T17:02:51.399725Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wine.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T17:02:51.460225Z",
     "start_time": "2022-12-01T17:02:51.415226Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "wine.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Imagine we want to attempt to estimate the perceived quality of a wine using these attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T17:02:51.475726Z",
     "start_time": "2022-12-01T17:02:51.461725Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "wine['quality'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T17:02:51.491225Z",
     "start_time": "2022-12-01T17:02:51.477226Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "wine['red_wine'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### üß† **Knowledge Check**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> Why are we using \"quality\" as the dependent variable (target)? Would it make sense for another feature to be the target instead?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Running the Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "First, we'll separate the data into our predictors (X) and target (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T17:02:51.506725Z",
     "start_time": "2022-12-01T17:02:51.492725Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wine_preds = wine.drop('quality', axis=1)\n",
    "wine_target = wine['quality']\n",
    "wine_preds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now we can perform our (multiple) linear regression!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Adding an Intercept (\"Bias\", \"Constant\") Term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "When we were looking at *simple* linear regression, we generally assumed that there would be an intercept term ($\\beta_0$) as well as a slope term ($\\beta_1$). That will be no less true for multiple linear regression. So this time let's add an intercept term. We can do that by simply adding a column of ones to our dataset, and `statsmodels` has a shortcut for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T17:02:51.537724Z",
     "start_time": "2022-12-01T17:02:51.508726Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# use sm.add_constant() to add constant term/y-intercept\n",
    "predictors = sm.add_constant(wine_preds)\n",
    "predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T17:02:51.553224Z",
     "start_time": "2022-12-01T17:02:51.539725Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = sm.OLS(wine_target, predictors).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> All right! So we fitted our model! Take a look at the summary and look if you can understand the different parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T17:02:51.584224Z",
     "start_time": "2022-12-01T17:02:51.554724Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Scaling - The Missing & Helpful Step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "When you looked at the summary after we did the linear regression, you might have noticed something interesting.\n",
    "\n",
    "Observing the coefficients, you might notice there are two relatively large coefficients and only one other is greater than 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## What's Going on Here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In a word, it's useful to have all of our variables be on the same scale, so that the resulting coefficients are easier to interpret. If the scales of the variables are very different one from another, then some of the coefficients may end up on very large or very tiny scales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This happens since the coefficients will effectively attempt to \"shrink\" or \"expand\" the features before factoring their importance to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "![](images/shrinkinator.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This can make it more difficult for interpretation and identifying coefficients with the most \"effect\" on the prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "For more on this, see [this post](https://stats.stackexchange.com/questions/32649/some-of-my-predictors-are-on-very-different-scales-do-i-need-to-transform-them)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## A Solution: Standard Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "One solution is to *scale* our features. There are a few ways to do this but we'll focus on **standard scaling**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "When we do **standard scaling**, we're really scaling it to be the features' respective $z$-scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Benefits:\n",
    "\n",
    "- This tends to make values relatively small (mean value is at $0$ and one standard deviation $\\sigma$ from the mean is $1$).\n",
    "- Easier interpretation: larger coefficients tend to be more influential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Interpretation of Coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's take a moment on this last point. Recall our interpretation of the linear regression coefficients (or betas): Suppose the coefficient for some predictor $x_1$ in a linear model is $\\beta_1$. That's then to say that for a one-unit increase in the value of $x_1$, the model predicts an increase in the target of $\\beta_1$ units.\n",
    "\n",
    "But let's now focus on this idea of *units*. Suppose I build a model of liver tumor size (mm) that includes body mass (kg) and fingernail length ($\\mu$m) as predictive features. And suppose further that the coefficients I find after fitting the model are:\n",
    "\n",
    "- body mass: 0.1\n",
    "- fingernail length: 0.1\n",
    "\n",
    "Now: Which variable is more important to predicting liver tumor size? The coefficients have the same value, but they have very different interpretations in this context. The first coefficient tells us that, for every *kilogram* increase of body mass, I should expect an increase in liver tumor size of 0.1 mm. The second coefficient tells us that, for every *micron* increase of fingernal length, I should expect an increase in liver tumor size of 0.1 mm. Since microns are so small, fingernail length is likely more important than body mass.\n",
    "\n",
    "Another thing to keep in mind here is that scaling recasts the values of a variable in terms of that variable's *standard deviation*. And so variables with greater spreads of values will typically be more important than variables with smaller spreads. (A variable with no spread can't explain much of anything!)\n",
    "\n",
    "We can remove much of the guess work about which variables are more important by standardizing, since that **puts all variables on the same scale and in units of their standard deviations**.\n",
    "\n",
    "We just have to remember to keep in mind this transformation when *interpreting* our coefficients. So suppose our variables' standard deviations are something like\n",
    "\n",
    "- body mass: 20 kg\n",
    "- fingernail length: 3000 $\\mu$m\n",
    "\n",
    "And suppose that after scaling we get coefficients that look like this:\n",
    "\n",
    "- body mass: 2\n",
    "- fingernail length: 300\n",
    "\n",
    "Then we can say that for every increase in body mass of 20 kg, we can expect an increase in liver tumor size of 2 mm, and for every increase in fingernail length of 3000 $\\mu$m, we can expect an increase in liver tumor size of 300 mm. And now these coefficients are comparable in the sense that they both reflect the variables' underlying spreads and distributions.\n",
    "\n",
    "For more on this topic, see also [this blog post](https://www.analyticsvidhya.com/blog/2021/03/standardized-vs-unstandardized-regression-coefficient/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Next time, let's *scale* our columns as $z$-scores first. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##  Redoing with Standard Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's try standard scaling the model with our wine dataset now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T17:02:51.599725Z",
     "start_time": "2022-12-01T17:02:51.585726Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# We'll include all the columns for now.\n",
    "\n",
    "wine_preds_scaled = (wine_preds - np.mean(wine_preds)) / np.std(wine_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T17:02:51.646225Z",
     "start_time": "2022-12-01T17:02:51.603726Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wine_preds_scaled.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T17:02:51.677225Z",
     "start_time": "2022-12-01T17:02:51.648726Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "predictors = sm.add_constant(wine_preds_scaled)\n",
    "model = sm.OLS(wine_target, predictors).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> Compare how well this model did with the one before scaling. Does it perform any differently?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T17:02:51.692724Z",
     "start_time": "2022-12-01T17:02:51.678725Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Notes here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### üß† **Knowledge Check**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> After standard scaling, what would it mean when all the $x_i$ are all $0$?\n",
    "\n",
    "> And what does this mean for the constant term $\\hat{\\beta}_0$? Could we check this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-01T17:02:51.708224Z",
     "start_time": "2022-12-01T17:02:51.694226Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "wine_target.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "TOC",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

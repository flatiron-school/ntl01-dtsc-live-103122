{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Objectives\" data-toc-modified-id=\"Objectives-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Objectives</a></span></li><li><span><a href=\"#Inheritance\" data-toc-modified-id=\"Inheritance-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Inheritance</a></span><ul class=\"toc-item\"><li><span><a href=\"#Motivation:-So-What's-the-Benefit?\" data-toc-modified-id=\"Motivation:-So-What's-the-Benefit?-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Motivation: So What's the Benefit?</a></span></li><li><span><a href=\"#Inheritance-in-Data-Science\" data-toc-modified-id=\"Inheritance-in-Data-Science-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Inheritance in Data Science</a></span></li></ul></li><li><span><a href=\"#Duck-Typing\" data-toc-modified-id=\"Duck-Typing-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Duck Typing</a></span><ul class=\"toc-item\"><li><span><a href=\"#Duck-Typing-in-Scikit-Learn\" data-toc-modified-id=\"Duck-Typing-in-Scikit-Learn-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Duck Typing in Scikit-Learn</a></span></li></ul></li><li><span><a href=\"#Scikit-Learn's-API:-(Estimators,-Transformers,-Predictors)\" data-toc-modified-id=\"Scikit-Learn's-API:-(Estimators,-Transformers,-Predictors)-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Scikit-Learn's API: (Estimators, Transformers, Predictors)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Estimator\" data-toc-modified-id=\"Estimator-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Estimator</a></span><ul class=\"toc-item\"><li><span><a href=\"#fit\" data-toc-modified-id=\"fit-4.1.1\"><span class=\"toc-item-num\">4.1.1&nbsp;&nbsp;</span><code>fit</code></a></span></li></ul></li><li><span><a href=\"#Transformer\" data-toc-modified-id=\"Transformer-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Transformer</a></span><ul class=\"toc-item\"><li><span><a href=\"#transform\" data-toc-modified-id=\"transform-4.2.1\"><span class=\"toc-item-num\">4.2.1&nbsp;&nbsp;</span><code>transform</code></a></span></li><li><span><a href=\"#fit_transform\" data-toc-modified-id=\"fit_transform-4.2.2\"><span class=\"toc-item-num\">4.2.2&nbsp;&nbsp;</span><code>fit_transform</code></a></span></li></ul></li><li><span><a href=\"#Predictor\" data-toc-modified-id=\"Predictor-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Predictor</a></span><ul class=\"toc-item\"><li><span><a href=\"#predict\" data-toc-modified-id=\"predict-4.3.1\"><span class=\"toc-item-num\">4.3.1&nbsp;&nbsp;</span><code>predict</code></a></span></li><li><span><a href=\"#score\" data-toc-modified-id=\"score-4.3.2\"><span class=\"toc-item-num\">4.3.2&nbsp;&nbsp;</span><code>score</code></a></span></li></ul></li><li><span><a href=\"#Observing-a-Scikit-Learn-Class-Definition-from-Source\" data-toc-modified-id=\"Observing-a-Scikit-Learn-Class-Definition-from-Source-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>Observing a Scikit-Learn Class Definition from Source</a></span></li></ul></li><li><span><a href=\"#Creating-a-Scikit-Learn-Transformer\" data-toc-modified-id=\"Creating-a-Scikit-Learn-Transformer-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Creating a Scikit-Learn Transformer</a></span><ul class=\"toc-item\"><li><span><a href=\"#Creating-a-New-Transformer\" data-toc-modified-id=\"Creating-a-New-Transformer-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Creating a New Transformer</a></span></li><li><span><a href=\"#Creating-a-fit-Method\" data-toc-modified-id=\"Creating-a-fit-Method-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Creating a <code>fit</code> Method</a></span></li><li><span><a href=\"#Creating-transform-Method\" data-toc-modified-id=\"Creating-transform-Method-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Creating <code>transform</code> Method</a></span></li><li><span><a href=\"#Conclusion\" data-toc-modified-id=\"Conclusion-5.4\"><span class=\"toc-item-num\">5.4&nbsp;&nbsp;</span>Conclusion</a></span></li></ul></li><li><span><a href=\"#Exercise:-Create-Your-Own-Transformer\" data-toc-modified-id=\"Exercise:-Create-Your-Own-Transformer-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Exercise: Create Your Own Transformer</a></span><ul class=\"toc-item\"><li><span><a href=\"#Test-Your-Code!\" data-toc-modified-id=\"Test-Your-Code!-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Test Your Code!</a></span></li><li><span><a href=\"#Objectives-Recap\" data-toc-modified-id=\"Objectives-Recap-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Objectives Recap</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-12T22:00:51.342548Z",
     "start_time": "2022-12-12T22:00:50.572049Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Understand the concept of object-oriented inheritance\n",
    "- Understand the main object types of the Scikit-Learn API\n",
    "- Extend and create custom Scikit-Learn Estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inheritance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've learned a lot already on object-oriented programming and how to create our own classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also define classes in terms of _other_ classes, in which case the new classes **inherit** the attributes and methods from the classes in terms of which they're defined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivation: So What's the Benefit? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_More abstraction is better_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at this code below. Look at how much we've already done:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-12T22:02:04.478448Z",
     "start_time": "2022-12-12T22:02:04.469948Z"
    }
   },
   "outputs": [],
   "source": [
    "# Look at all that code we wrote... do we have to do it all again...?\n",
    "class Robot():\n",
    "\n",
    "    \n",
    "    # We'd like to start off with some initial attributes\n",
    "    def __init__(self, first_name='?', last_name=''):\n",
    "        \n",
    "        # Clean the names of extra spaces at beginning & end\n",
    "        first_name = first_name.strip()\n",
    "        last_name = last_name.strip()    \n",
    "        \n",
    "        # Setting attributes\n",
    "        self._first_name = first_name\n",
    "        self._last_name = last_name\n",
    "        \n",
    "        # Combine first and last names and remove any extra spacing\n",
    "        self.name = ' '.join([first_name,last_name]).strip()\n",
    "        \n",
    "        self.purpose = 'To love humans'\n",
    "\n",
    "           \n",
    "    def change_name(self, new_name):\n",
    "        self.name = new_name\n",
    "    \n",
    "    def speak(self):\n",
    "        print(f'I am {self.name}!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we wanted to make another bot with some extra functionality like keeping track of its battery charge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do we have to copy and paste this and then add our new functionality? \n",
    "\n",
    "Nope! Since we can abstract away the stuff we already did!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-12T22:03:14.254119Z",
     "start_time": "2022-12-12T22:03:14.249619Z"
    }
   },
   "outputs": [],
   "source": [
    "class GarbageBot(Robot): # Specify the base class(es) we inherit from\n",
    "    '''A robot that takes care of garbage while we're away!'''\n",
    "    \n",
    "    battery = 100\n",
    "    \n",
    "    def speak(self):\n",
    "        print(f\"I'm {self.name} and have {self.battery}% battery charged\")\n",
    "        self.battery -= 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-12T22:03:47.523205Z",
     "start_time": "2022-12-12T22:03:47.508206Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiate\n",
    "\n",
    "new_robot = GarbageBot('Wall-e')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-12T22:03:54.015608Z",
     "start_time": "2022-12-12T22:03:54.005110Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm Wall-e and have 100% battery charged\n"
     ]
    }
   ],
   "source": [
    "new_robot.speak()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And I still keep the other functionality from the original class!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-12T22:04:23.399525Z",
     "start_time": "2022-12-12T22:04:23.383560Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm E-llaw and have 90% battery charged\n"
     ]
    }
   ],
   "source": [
    "# Change Name\n",
    "new_robot.change_name('E-llaw') # Note we never defined this in GarbageBot!\n",
    "new_robot.speak()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inheritance in Data Science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of motivation in how we write our code can be summed up with, \"Never reinvent the wheel\". And using **inheritance** can make this really easy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Later, we'll be taking Scikit-Learn's objects and customizing them to our particular needs. This can be a common practice as we use libraries and tools to write reproducible code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inheritance allows us to write some of this code quickly by avoiding a lot of \"boilerplate\" code (the same code we write over and over just to do a minor change)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Duck Typing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we don't need inheritance to do everything. \n",
    "\n",
    "A different method of getting functionality using different objects is called **duck typing**. The term comes from the saying: \n",
    "> **\"If it walks like a duck and it quacks like a duck, then it must be a duck.\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/duck.jpg)\n",
    "> <a href=\"https://commons.wikimedia.org/wiki/File:Rubber_Duck_Front_View_in_Fine_Day_20140107.jpg\">玄史生</a>, <a href=\"https://creativecommons.org/licenses/by-sa/3.0\">CC BY-SA 3.0</a>, via Wikimedia Commons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you're using the concept of duck typing, you really don't care about the object _type_ and if it's compatible.\n",
    "\n",
    "All you _care about are the **methods and properties**_ of the object over the type or even class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duck Typing in Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-Learn relies more on duck typing over pure inheritance. In general, if an object has certain methods that `sklearn` expects, than it's mostly compatible!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, inheritance in Scikit-Learn is typically used to avoid _boilerplate_ code. Usually this involves using [`sklearn.base`](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.base) such as [`sklearn.base.BaseEstimator`](https://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html#sklearn.base.BaseEstimator)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-Learn's API: (Estimators, Transformers, Predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-Learn has a great [API](https://scikit-learn.org/stable/developers/develop.html) that has objects that are consistent and easy to make compatible with your own made objects!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go over the API's object that will be most relevant to us in the near future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This is an object that can can take in data and _estimate_ (or *learn*) some parameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means regression and classification models are estimators but so are objects that transform the original dataset ([Transformers](#Transformer)) such as `StandardScaler`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `fit`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All estimators estimate/learn by calling the `fit()` method by passing in the dataset. Other parameters can be passed in to \"help\" the estimator to learn. These are called **hyperparameters**, parameters used to tweak the learning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "\n",
    "ss.fit(X_train)\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Some estimators can change the original data to something new, a **transformation**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can think of examples of these **transformers** when you do scaling, data cleaning, or expanding/reducing on a dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `transform`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformers will call the `transform()` method to apply the transformation to a dataset after a `fit()` call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  `fit_transform`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that all estimators have a `fit()` method, so a transformer can use the `fit()` method to learn something about the given dataset. After learning with `fit()`, a transformation on the dataset can be made with the `transform()` method. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example of this would be a function that performs normalization on the dataset; the `fit()` method would learn the minimum and maximum of the dataset and the `transform()` method will scale the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you call `fit` and `transform` with the same dataset, you can simply call the `fit_transform()` method. This essentially has the same results as calling `fit()` and then `transform()` on the dataset but possibly with some optimization and efficiencies baked in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandScaler()\n",
    "ss.fit(X_train)\n",
    "ss.transform(X_train)\n",
    "\n",
    "X_tr_sc = ss.fit_transform(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We would use the `fit()` method to train our predictor object and then feed in new data to make predictions (based on what it learned in the fitting stage)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've used **predictors** whenever we've made predictions like with a `LinearRegression` model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `predict`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you probably can guess, the `predict()` method predicts results from a dataset given to it after being trained with a `fit()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `score`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictors also have a `score()` method that can be used to evaluate how well the predictor performed on a dataset (such as the test set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observing a Scikit-Learn Class Definition from Source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin by taking a look at the source code for `sklearn`'s [StandardScaler](https://github.com/scikit-learn/scikit-learn/blob/fd237278e/sklearn/preprocessing/_data.py#L517)\n",
    "\n",
    "Take a minute to peruse the source code on your own. What do you notice?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Scikit-Learn Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Sometimes we want to create our own Scikit-Learn objects to be used in our code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to create a new _transformer_ that will transform the data in the following manner:\n",
    "\n",
    "- If the value is **positive**, scale the value by the **largest value** in that column\n",
    "- If the value is **negative**, change it to $0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a New Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we create our base estimator/transformer through inheritance of [`sklearn.base.BaseEstimator`](https://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html#sklearn.base.BaseEstimator):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-12T22:29:45.526541Z",
     "start_time": "2022-12-12T22:29:45.519542Z"
    }
   },
   "outputs": [],
   "source": [
    "# Base Class\n",
    "\n",
    "class SpecialTransformer(BaseEstimator):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-12T22:29:57.783540Z",
     "start_time": "2022-12-12T22:29:57.775541Z"
    }
   },
   "outputs": [],
   "source": [
    "spec_t = SpecialTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-12T22:30:00.341041Z",
     "start_time": "2022-12-12T22:30:00.320541Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpecialTransformer()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spec_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This by itself is pretty useless. But we can now add in new `fit()` method which will find the maximum value for each column/feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a `fit` Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-12T22:33:43.381176Z",
     "start_time": "2022-12-12T22:33:43.372676Z"
    }
   },
   "outputs": [],
   "source": [
    "# fit\n",
    "\n",
    "class SpecialTransformer(BaseEstimator):\n",
    "    \n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        \n",
    "        self.max_ = np.max(X, axis=0)\n",
    "        \n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-12T22:33:55.636676Z",
     "start_time": "2022-12-12T22:33:55.624676Z"
    }
   },
   "outputs": [],
   "source": [
    "# instantiate\n",
    "spec_t = SpecialTransformer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-12T22:42:13.843020Z",
     "start_time": "2022-12-12T22:42:13.827522Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  -4,  400,   40],\n",
       "       [  10, -100,    1],\n",
       "       [   6, -800,  700],\n",
       "       [   2,    0,  400],\n",
       "       [   8,  200, 1000]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Let's use some test data\n",
    "# Note each column is a feature, each row a data point\n",
    "X = np.array([\n",
    "    [-4, 400, 40],\n",
    "    [10, -100, 1],\n",
    "    [6, -800, 700],\n",
    "    [2, 0, 400],\n",
    "    [8, 200, 1000]\n",
    "])\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Quick check: What would be the max values for each column/feature?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-12T22:33:57.743206Z",
     "start_time": "2022-12-12T22:33:57.721175Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SpecialTransformer' object has no attribute 'max_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-08e6f61fc612>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mspec_t\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'SpecialTransformer' object has no attribute 'max_'"
     ]
    }
   ],
   "source": [
    "spec_t.max_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-12T22:33:58.533176Z",
     "start_time": "2022-12-12T22:33:58.521676Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpecialTransformer()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spec_t.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-12T22:34:00.454676Z",
     "start_time": "2022-12-12T22:34:00.447676Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  10,  400, 1000])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check .max_\n",
    "spec_t.max_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No transformation yet, but finds the maximum values, fit and check\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating `transform` Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now actually implement a way to transform our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-12T22:42:02.050552Z",
     "start_time": "2022-12-12T22:42:02.033522Z"
    }
   },
   "outputs": [],
   "source": [
    "# add transform\n",
    "class SpecialTransformer(BaseEstimator):\n",
    "    \n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.max_ = np.max(X, axis=0)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        '''\n",
    "        Scale the values passed in: \n",
    "            - Negatives go to 0\n",
    "            - Positives scaled by maximum value found in fit()\n",
    "        '''\n",
    "        \n",
    "        X_copy = np.copy(X)\n",
    "        \n",
    "        X_copy[  X_copy < 0   ] = 0\n",
    "        \n",
    "        X_scaled = X_copy / self.max_\n",
    "        \n",
    "        return X_scaled\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-12T22:41:39.168521Z",
     "start_time": "2022-12-12T22:41:39.165022Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  -4,  400,   40],\n",
       "       [  10, -100,    1],\n",
       "       [   6, -800,  700],\n",
       "       [   2,    0,  400],\n",
       "       [   8,  200, 1000]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-12T22:41:39.803523Z",
     "start_time": "2022-12-12T22:41:39.798021Z"
    }
   },
   "outputs": [],
   "source": [
    "X[ X<0 ] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-12T22:41:40.407523Z",
     "start_time": "2022-12-12T22:41:40.393522Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,  400,   40],\n",
       "       [  10,    0,    1],\n",
       "       [   6,    0,  700],\n",
       "       [   2,    0,  400],\n",
       "       [   8,  200, 1000]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-12T22:41:49.718021Z",
     "start_time": "2022-12-12T22:41:49.708022Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.   , 1.   , 0.04 ],\n",
       "       [1.   , 0.   , 0.001],\n",
       "       [0.6  , 0.   , 0.7  ],\n",
       "       [0.2  , 0.   , 0.4  ],\n",
       "       [0.8  , 0.5  , 1.   ]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X / np.array([  10,  400, 1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-12T22:42:17.701021Z",
     "start_time": "2022-12-12T22:42:17.686022Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  -4,  400,   40],\n",
       "       [  10, -100,    1],\n",
       "       [   6, -800,  700],\n",
       "       [   2,    0,  400],\n",
       "       [   8,  200, 1000]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recall the data\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-12T22:42:30.329021Z",
     "start_time": "2022-12-12T22:42:30.321522Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a SpecialTransformer and fit with the data\n",
    "spec_t = SpecialTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-12T22:43:08.257203Z",
     "start_time": "2022-12-12T22:43:08.242361Z"
    }
   },
   "outputs": [],
   "source": [
    "# Transform the data\n",
    "spec_t.fit(X)\n",
    "X_trans = spec_t.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-12T22:43:10.845025Z",
     "start_time": "2022-12-12T22:43:10.833552Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.   , 1.   , 0.04 ],\n",
       "       [1.   , 0.   , 0.001],\n",
       "       [0.6  , 0.   , 0.7  ],\n",
       "       [0.2  , 0.   , 0.4  ],\n",
       "       [0.8  , 0.5  , 1.   ]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-12T22:42:56.592194Z",
     "start_time": "2022-12-12T22:42:56.585693Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  -4,  400,   40],\n",
       "       [  10, -100,    1],\n",
       "       [   6, -800,  700],\n",
       "       [   2,    0,  400],\n",
       "       [   8,  200, 1000]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now created our very own transformer! We could even feed in one data set to _fit_ our object and then a different dataset to _transform_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should note that there's still a lot of customization we could have done. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, we didn't consider what happens if the maximum value for a feature was $0$. We really should code how we want that to be handled (but we just ignored it for now)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also could have gotten the `fit_transform()` method automatically by also inheriting from [`TransformerMixin`](https://scikit-learn.org/stable/modules/generated/sklearn.base.TransformerMixin.html#sklearn.base.TransformerMixin). See the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-12T22:45:07.583864Z",
     "start_time": "2022-12-12T22:45:07.570364Z"
    }
   },
   "outputs": [],
   "source": [
    "class SpecialTransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.max_ = np.max(X,axis=0) \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X_copy = np.copy(X)\n",
    "        X_copy[X_copy < 0] = 0\n",
    "        return X_copy / self.max_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-12T22:45:13.904864Z",
     "start_time": "2022-12-12T22:45:13.894369Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.   , 1.   , 0.04 ],\n",
       "       [1.   , 0.   , 0.001],\n",
       "       [0.6  , 0.   , 0.7  ],\n",
       "       [0.2  , 0.   , 0.4  ],\n",
       "       [0.8  , 0.5  , 1.   ]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_special_trans = SpecialTransformer()\n",
    "# Note we can now do fit_transform()\n",
    "X_new = my_special_trans.fit_transform(X)\n",
    "X_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise: Create Your Own Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your turn! Let's try to recreate the [`StandardScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) object!\n",
    "\n",
    "Recall that standard scaling transforms the values in the following way:\n",
    "\n",
    "$$x_i = \\frac{x_i-\\bar{x_i}}{\\sigma_{x_i}}$$\n",
    "\n",
    "where the $i$ subscript reminds us that it comes from a single column/feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE!\n",
    "class MyStandardScaler:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Answer</summary>\n",
    "        <code>class MyStandardScaler:\n",
    "    def fit(self, arr):\n",
    "        self.mean_ = np.mean(arr, axis=0)\n",
    "        self.scale_ = np.std(arr, axis=0)\n",
    "    def transform(self, arr):\n",
    "        return (arr - self.mean_) / self.scale_</code>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-12T23:13:18.430644Z",
     "start_time": "2022-12-12T23:13:18.419644Z"
    }
   },
   "outputs": [],
   "source": [
    "# Jonathon/Roshni\n",
    "\n",
    "class MyStandardScaler(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        self.mean_ = np.mean(X, axis=0)\n",
    "        self.std_ = np.std(X, axis=0)\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X):\n",
    "        X_copy = np.copy(X)\n",
    "        return (X_copy - self.mean_) / self.std_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-12T23:15:01.592148Z",
     "start_time": "2022-12-12T23:15:01.575644Z"
    }
   },
   "outputs": [],
   "source": [
    "test = MyStandardScaler()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-12T23:15:44.190645Z",
     "start_time": "2022-12-12T23:15:44.183149Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.69222822,  1.12766778, -1.01262497],\n",
       "       [ 1.12815215, -0.09805807, -1.114357  ],\n",
       "       [ 0.32232919, -1.81407425,  0.70899399],\n",
       "       [-0.48349378,  0.1470871 , -0.07356008],\n",
       "       [ 0.72524067,  0.63737744,  1.49154806]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Your Code!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have it, you can test it against the data below and Scikit-Learn's `StandardScaler`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-12T23:13:23.465143Z",
     "start_time": "2022-12-12T23:13:23.458644Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  -4,  400,   40],\n",
       "       [  10, -100,    1],\n",
       "       [   6, -800,  700],\n",
       "       [   2,    0,  400],\n",
       "       [   8,  200, 1000]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your test data\n",
    "X = np.array([\n",
    "    [-4, 400, 40],\n",
    "    [10, -100, 1],\n",
    "    [6, -800, 700],\n",
    "    [2, 0, 400],\n",
    "    [8, 200, 1000]\n",
    "])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-12T23:13:25.030143Z",
     "start_time": "2022-12-12T23:13:25.009643Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.69222822,  1.12766778, -1.01262497],\n",
       "       [ 1.12815215, -0.09805807, -1.114357  ],\n",
       "       [ 0.32232919, -1.81407425,  0.70899399],\n",
       "       [-0.48349378,  0.1470871 , -0.07356008],\n",
       "       [ 0.72524067,  0.63737744,  1.49154806]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test against StandardScaler\n",
    "sklearn_scaler = StandardScaler()\n",
    "X_sklearn_scaled = sklearn_scaler.fit_transform(X)\n",
    "X_sklearn_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-12T23:13:32.173838Z",
     "start_time": "2022-12-12T23:13:32.165144Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler and MyStandardScaler same?\n",
      "[[ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]]\n"
     ]
    }
   ],
   "source": [
    "# Catches errors\n",
    "try:\n",
    "    # Your implementation\n",
    "    my_scaler = MyStandardScaler()\n",
    "    my_scaler.fit(X)\n",
    "    X_my_scaled = my_scaler.transform(X)\n",
    "    \n",
    "    # Check against StandardScaler\n",
    "    print('StandardScaler and MyStandardScaler same?')\n",
    "    print(X_sklearn_scaled == X_my_scaled)\n",
    "except:\n",
    "    print('Check your fit() and transform() methods!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Objectives Recap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Understand the concept of object-oriented inheritance\n",
    "- Understand the main object types of the Scikit-Learn API\n",
    "- Extend and create custom Scikit-Learn Estimators"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

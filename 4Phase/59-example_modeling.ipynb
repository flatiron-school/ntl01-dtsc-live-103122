{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Learning-Goals\" data-toc-modified-id=\"Learning-Goals-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Learning Goals</a></span></li><li><span><a href=\"#Time-Series-Models\" data-toc-modified-id=\"Time-Series-Models-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Time Series Models</a></span><ul class=\"toc-item\"><li><span><a href=\"#Chicago-Gun-Data\" data-toc-modified-id=\"Chicago-Gun-Data-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Chicago Gun Data</a></span><ul class=\"toc-item\"><li><span><a href=\"#sklearn.model_selection.TimeSeriesSplit\" data-toc-modified-id=\"sklearn.model_selection.TimeSeriesSplit-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span><code>sklearn.model_selection.TimeSeriesSplit</code></a></span></li></ul></li><li><span><a href=\"#Baseline\" data-toc-modified-id=\"Baseline-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Baseline</a></span></li><li><span><a href=\"#The-Autoregressive-Model-(AR)\" data-toc-modified-id=\"The-Autoregressive-Model-(AR)-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>The Autoregressive Model (AR)</a></span><ul class=\"toc-item\"><li><span><a href=\"#statsmodels.tsa.arima_model.ARIMA\" data-toc-modified-id=\"statsmodels.tsa.arima_model.ARIMA-2.3.1\"><span class=\"toc-item-num\">2.3.1&nbsp;&nbsp;</span><a href=\"https://www.statsmodels.org/devel/generated/statsmodels.tsa.arima.model.ARIMA.html\" target=\"_blank\"><code>statsmodels.tsa.arima_model.ARIMA</code></a></a></span></li><li><span><a href=\"#Sidebar:-Akaike-Information-Criterion\" data-toc-modified-id=\"Sidebar:-Akaike-Information-Criterion-2.3.2\"><span class=\"toc-item-num\">2.3.2&nbsp;&nbsp;</span>Sidebar: Akaike Information Criterion</a></span></li><li><span><a href=\"#Cross-Validation\" data-toc-modified-id=\"Cross-Validation-2.3.3\"><span class=\"toc-item-num\">2.3.3&nbsp;&nbsp;</span>Cross-Validation</a></span></li><li><span><a href=\"#Comparison-with-sklearn.linear_model.LinearRegression\" data-toc-modified-id=\"Comparison-with-sklearn.linear_model.LinearRegression-2.3.4\"><span class=\"toc-item-num\">2.3.4&nbsp;&nbsp;</span>Comparison with <code>sklearn.linear_model.LinearRegression</code></a></span></li><li><span><a href=\"#Adding-a-Term\" data-toc-modified-id=\"Adding-a-Term-2.3.5\"><span class=\"toc-item-num\">2.3.5&nbsp;&nbsp;</span>Adding a Term</a></span></li></ul></li><li><span><a href=\"#Moving-Average-Model-(MA)\" data-toc-modified-id=\"Moving-Average-Model-(MA)-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Moving Average Model (MA)</a></span></li><li><span><a href=\"#ARMA\" data-toc-modified-id=\"ARMA-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>ARMA</a></span></li></ul></li><li><span><a href=\"#LEVEL-UPS\" data-toc-modified-id=\"LEVEL-UPS-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>LEVEL UPS</a></span><ul class=\"toc-item\"><li><span><a href=\"#ACF-and-PACF\" data-toc-modified-id=\"ACF-and-PACF-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>ACF and PACF</a></span><ul class=\"toc-item\"><li><span><a href=\"#PACF\" data-toc-modified-id=\"PACF-3.1.1\"><span class=\"toc-item-num\">3.1.1&nbsp;&nbsp;</span>PACF</a></span></li><li><span><a href=\"#ACF\" data-toc-modified-id=\"ACF-3.1.2\"><span class=\"toc-item-num\">3.1.2&nbsp;&nbsp;</span>ACF</a></span></li></ul></li><li><span><a href=\"#Testing\" data-toc-modified-id=\"Testing-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Testing</a></span></li><li><span><a href=\"#SARIMA\" data-toc-modified-id=\"SARIMA-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>SARIMA</a></span></li><li><span><a href=\"#Forecast\" data-toc-modified-id=\"Forecast-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Forecast</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Learning Goals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Build time-series models with `statsmodels`\n",
    "- Cross-validate time-series models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Time Series Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from random import gauss as gs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "import itertools\n",
    "#from pmdarima import auto_arima\n",
    "\n",
    "#statsmodels\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.stattools import acf, pacf, adfuller\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def display_df(dftest):\n",
    "    '''\n",
    "    Display the output from a Dickey-Fuller test in a more readable format\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    dfoutput = pd.Series(\n",
    "                dftest[0:4], \n",
    "                index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n",
    "\n",
    "    for key,value in dftest[4].items():\n",
    "        dfoutput['Critical Value (%s)'%key] = value\n",
    "\n",
    "    display(dfoutput)\n",
    "    \n",
    "    print(f\"The p-value associated with the Dickey-Fuller statistical test is {dfoutput['p-value']},\")\n",
    "    if dfoutput['p-value'] < 0.05:\n",
    "        print(\" so we can safely assume that the differenced data is stationary.\")\n",
    "    else:\n",
    "        print(\" so we cannot reject the null hypothesis that the differenced data is \\\n",
    "    not stationary.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Chicago Gun Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's reimport our chicago gun crime data, and prepare it in the same manner as the last notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ts = pd.read_csv('data/Gun_Crimes_Heat_Map.csv')\n",
    "ts['Date'] = pd.to_datetime(ts.Date)\n",
    "ts_minute = ts.groupby('Date').count()['ID']\n",
    "daily_count = ts_minute.resample('D').sum()\n",
    "daily_count = daily_count[daily_count < 90]\n",
    "\n",
    "ts_dr = pd.date_range(daily_count.index[0], daily_count.index[-1])\n",
    "ts_daily = np.empty(shape=len(ts_dr))\n",
    "ts_daily = pd.Series(ts_daily)\n",
    "ts_daily = ts_daily.reindex(ts_dr)\n",
    "ts_daily = ts_daily.fillna(daily_count)\n",
    "ts_daily = ts_daily.interpolate()\n",
    "\n",
    "ts_weekly = ts_daily.resample('W').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(ts_weekly)\n",
    "ax.set_title(\"Weekly Reports of Gun Offenses in Chicago\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The train-test split for a time series is a little different from what we are used to. Because **chronological order matters**, we cannot randomly sample points in our data. Instead, we cut off a portion of our data at the end, and reserve it as our test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# find the index which allows us to split off 20% of the data\n",
    "cutoff = round(ts_weekly.shape[0]*0.8)\n",
    "cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Define train and test sets according to the index found above\n",
    "train = ts_weekly[:cutoff]\n",
    "\n",
    "test = ts_weekly[cutoff:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Plot it!\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "ax.plot(train, label='train')\n",
    "ax.plot(test, label='test')\n",
    "ax.set_title('Train-Test Split');\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### `sklearn.model_selection.TimeSeriesSplit`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's also use `sklearn`'s in-built class to prepare our model for a kind of cross-validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# TimeSeriesSplit\n",
    "split = TimeSeriesSplit()\n",
    "\n",
    "for train_ind, val_ind in split.split(train):\n",
    "    print('Train Idices:')\n",
    "    print(train_ind)\n",
    "    print('Validation Indices:')\n",
    "    print(val_ind)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We will now set aside our test set, and build our model on the train."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# we can perform this with the shift operator\n",
    "# The prediction for the next day is the original series shifted to the future by one day.\n",
    "naive = train.shift(1)\n",
    "naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "train[0:30].plot(ax=ax, c='r', label='original')\n",
    "naive[0:30].plot(ax=ax, c='b', label='shifted')\n",
    "ax.set_title('naive')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "For a baseline to compare our later models, lets calculate our **RMSE** for the naive model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.sqrt(mean_squared_error(train[1:], naive.dropna()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "residuals = naive[1:] - train[1:]\n",
    "ax.plot(residuals.index, residuals, label='resid')\n",
    "ax.plot(residuals.index, residuals.rolling(30).std(), label='rolling std')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(residuals.index, residuals, label='resid')\n",
    "ax.plot(residuals.index, residuals.rolling(30).var(), label='rolling var')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "If we look at the rolling standard deviation of our errors, we can see that the performance of our model varies at different points in time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "That is a result of the trends in our data.\n",
    "\n",
    "In the previous notebook, we were able to make our series **stationary** by differencing our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Visually, our differenced data looks *more* like white noise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(train.diff())\n",
    "ax.set_title('Weekly differenced data');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "By removing the trend from our data, we assume that our data's mean and variance are constant throughout.  But it is **not** just white noise.  If it were, our models could do no better than random predictions around the mean.  \n",
    "\n",
    "Our task now is to find **more patterns** in the series.  \n",
    "\n",
    "We will focus on the data points near to the point in question.  We can attempt to find patterns to how much influence previous points in the sequence have. \n",
    "\n",
    "If that made you think of regression, great! What we will be doing is assigning weights, like our betas, to previous points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's make sure our data after differencing is stationary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dftest = adfuller(train.diff()[1:])\n",
    "display_df(dftest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## The Autoregressive Model (AR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### [`statsmodels.tsa.arima_model.ARIMA`](https://www.statsmodels.org/devel/generated/statsmodels.tsa.arima.model.ARIMA.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This model is really a compound of two simpler models. This ARIMA class takes a triple of values as its \"order\". We'll explain this shortly, but for now just note that the first member of the triple, i.e. the **p** variable of the order (p, d, q), represents the AR term. So for a first-order AR model, we'll put a 1 there.\n",
    "\n",
    "The 1 in the second place of the order will do our differencing for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# ar_1 model with differencing\n",
    "ar_1 = ARIMA(train, order=(1, 1, 0)).fit()\n",
    "\n",
    "# We put a typ='levels' to convert our predictions to remove the differencing performed.\n",
    "ar_1.predict(typ='levels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The ARIMA class comes with a nice summary table.  \n",
    "\n",
    "[This](https://analyzingalpha.com/interpret-arima-results/) does an excellent job going through the table and explaining the bits and bobs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Summary\n",
    "ar_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ar_1.aic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Sidebar: Akaike Information Criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "But, as you may notice, the output does not include RMSE.\n",
    "\n",
    "It does include [AIC](https://en.wikipedia.org/wiki/Akaike_information_criterion). A better model has a lower AIC.\n",
    "\n",
    "Let's compare the first order autoregressive model to our Random Walk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "random_walk_model = ARIMA(train, order=(0, 1, 0)).fit()\n",
    "random_walk_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Baseline ARIMA model\n",
    "baseline = ARIMA(train, order=(0,0,0)).fit()\n",
    "bl_preds = baseline.predict(typ='levels')\n",
    "bl_rmse = np.sqrt(mean_squared_error(train, bl_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(f'Baseline AIC: {baseline.aic}')\n",
    "print(f'Random Walk AIC: {random_walk_model.aic}')\n",
    "print(f'AR(1, 1, 0) AIC: {ar_1.aic}' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Our AIC for the AR(1) model is lower than the random walk, indicating improvement.  \n",
    "\n",
    "Let's also check the RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_hat_ar1 = ar_1.predict(typ='levels')\n",
    "ar1_rmse = np.sqrt(mean_squared_error(train, y_hat_ar1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_hat_rw = random_walk_model.predict(typ='levels')\n",
    "rw_rmse = np.sqrt(mean_squared_error(train, y_hat_rw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(f'Baseline RMSE:    {bl_rmse}')\n",
    "print(f'Random Walk RMSE: {rw_rmse}')\n",
    "print(f'AR1 RMSE:         {ar1_rmse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "RMSE is lower as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "For this it will help to have our normal integer index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_with_ind = train.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for train_ind, val_ind in split.split(train_with_ind):\n",
    "    ar = ARIMA(endog=train_with_ind.iloc[train_ind, -1], order=(1, 1, 0)).fit()\n",
    "    preds = ar.predict(typ='levels', start=val_ind[0], end=val_ind[-1])\n",
    "    true = train_with_ind.iloc[val_ind, -1]\n",
    "    print(np.sqrt(mean_squared_error(true, preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Comparison with `sklearn.linear_model.LinearRegression`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Autoregression, as we said before, is a regression of a time series on lagged values of itself.  \n",
    "\n",
    "From the summary, we see the coefficient of the 1st lag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ar_1.arparams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We come close to reproducing this coefficient with linear regression, with slight differences due to how statsmodels performs the regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(np.array(train.diff().shift(1).dropna()).reshape(-1, 1), train[1:].diff().dropna())\n",
    "print(lr.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Adding a Term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can also factor in more than just the most recent point.\n",
    "$$\\large y_{t} = \\phi_{0} + \\phi_{1}y_{t-1} + \\phi_{2}y_{t-2}+ \\varepsilon_{t}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We refer to the order of our AR model by the number of lags back we go.  The above formula refers to an **AR(2)** model. We put a 2 in the p position of the ARIMA class order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ar_2 = ARIMA(train, order=(2, 1, 0)).fit()\n",
    "\n",
    "ar_2.predict(typ='levels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(baseline.aic)\n",
    "print(random_walk_model.aic)\n",
    "print(ar_1.aic)\n",
    "print(ar_2.aic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_hat_ar1 = ar_2.predict(typ='levels')\n",
    "ar2_rmse = np.sqrt(mean_squared_error(train, y_hat_ar1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(f'Baseline RMSE:    {bl_rmse}')\n",
    "print(f'Random Walk RMSE: {rw_rmse}')\n",
    "print(f'AR1 RMSE:         {ar1_rmse}')\n",
    "print(f'AR2 RMSE:         {ar2_rmse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Our AIC improves with more lagged terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for train_ind, val_ind in split.split(train_with_ind):\n",
    "    ar = ARIMA(endog=train_with_ind.iloc[train_ind, -1], order=(2, 1, 0)).fit()\n",
    "    preds = ar.predict(typ='levels', start=val_ind[0], end=val_ind[-1])\n",
    "    true = train_with_ind.iloc[val_ind, -1]\n",
    "    print(np.sqrt(mean_squared_error(true, preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This is better on four out of five validation tests compared to the one-term model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Moving Average Model (MA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The next type of model is based on error.  The idea behind the moving average model is to make a prediction based on how far off we were the day before.\n",
    "\n",
    "$$\\large Y_t = \\mu +\\epsilon_t + \\theta\\epsilon_{t-1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The moving average model works like this. We make a prediction, see how far off we were, then adjust our next prediction by a factor of how far off our pervious prediction was.\n",
    "\n",
    "In our ARIMA model, the q term of our order (p, d, q) refers to the MA component. To use one lagged error, we put 1 in the q position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ma_1 = ARIMA(train, order=(0, 0, 1)).fit()\n",
    "y_hat = ma_1.predict(typ='levels')\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ma_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's look at the 1st order MA model with a 1st order difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ma_1 = ARIMA(train, order=(0, 1, 1)).fit()\n",
    "print(baseline.aic)\n",
    "print(random_walk_model.aic)\n",
    "print(ar_1.aic)\n",
    "print(ar_2.aic)\n",
    "print(ma_1.aic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_hat_ar1 = ma_1.predict(typ='levels')\n",
    "ma1_rmse = np.sqrt(mean_squared_error(train, y_hat_ar1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(f'Baseline RMSE:    {bl_rmse}')\n",
    "print(f'Random Walk RMSE: {rw_rmse}')\n",
    "print(f'AR1 RMSE:         {ar1_rmse}')\n",
    "print(f'AR2 RMSE:         {ar2_rmse}')\n",
    "print(f'MA1 RMSE:         {ma1_rmse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "It performs better than our AR(1) model and comparably to our AR(2) model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for train_ind, val_ind in split.split(train_with_ind):\n",
    "    ar = ARIMA(endog=train_with_ind.iloc[train_ind, -1], order=(0, 1, 1)).fit()\n",
    "    preds = ar.predict(typ='levels', start=val_ind[0], end=val_ind[-1])\n",
    "    true = train_with_ind.iloc[val_ind, -1]\n",
    "    print(np.sqrt(mean_squared_error(true, preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Just like our AR models, we can lag back as far as we want. Our MA(2) model would use the past two lagged terms:\n",
    "\n",
    "$$\\large Y_t = \\mu +\\epsilon_t + \\theta_1\\epsilon_{t-1} + \\theta_2\\epsilon_{t-2}$$\n",
    "\n",
    "and our MA term would be two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ma_2 = ARIMA(train, order=(0, 1, 2)).fit()\n",
    "y_hat = ma_2.predict(typ='levels')\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(random_walk_model.aic)\n",
    "print(ar_1.aic)\n",
    "print(ar_2.aic)\n",
    "print(ma_1.aic)\n",
    "print(ma_2.aic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_hat_ar1 = ma_2.predict(typ='levels')\n",
    "ma2_rmse = np.sqrt(mean_squared_error(train, y_hat_ar1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(f'Baseline RMSE:    {bl_rmse}')\n",
    "print(f'Random Walk RMSE: {rw_rmse}')\n",
    "print(f'AR1 RMSE:         {ar1_rmse}')\n",
    "print(f'AR2 RMSE:         {ar2_rmse}')\n",
    "print(f'MA1 RMSE:         {ma1_rmse}')\n",
    "print(f'MA2 RMSE:         {ma2_rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for train_ind, val_ind in split.split(train_with_ind):\n",
    "    ar = ARIMA(endog=train_with_ind.iloc[train_ind, -1], order=(0, 1, 2)).fit()\n",
    "    preds = ar.predict(typ='levels', start=val_ind[0], end=val_ind[-1])\n",
    "    true = train_with_ind.iloc[val_ind, -1]\n",
    "    print(np.sqrt(mean_squared_error(true, preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## ARMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We don't have to limit ourselves to just AR or MA.  We can use both AR terms and MA terms.\n",
    "\n",
    "for example, an ARMA(2, 2) model is given by:\n",
    "\n",
    " $$\\large Y_t = \\mu+\\phi_1 Y_{t-1}+\\phi_2 Y_{t-2}+\\theta_1\\epsilon_{t-1}+\\theta_2\\epsilon_{t-2}+\\epsilon_t$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "arma_21 = ARIMA(train, order=(2, 1, 2)).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(baseline.aic)\n",
    "print(random_walk_model.aic)\n",
    "print(ar_1.aic)\n",
    "print(ar_2.aic)\n",
    "print(ma_1.aic)\n",
    "print(ma_2.aic)\n",
    "print(arma_21.aic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def find_rmse(model, train_data=train):\n",
    "    y_hat = model.predict(typ='levels')\n",
    "    return np.sqrt(mean_squared_error(train_data, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(find_rmse(baseline))\n",
    "print(find_rmse(random_walk_model))\n",
    "print(find_rmse(ar_1))\n",
    "print(find_rmse(ar_2))\n",
    "print(find_rmse(ma_1))\n",
    "print(find_rmse(ma_2))\n",
    "print(find_rmse(arma_21))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for train_ind, val_ind in split.split(train_with_ind):\n",
    "    ar = ARIMA(endog=train_with_ind.iloc[train_ind, -1], order=(2, 1, 2)).fit()\n",
    "    preds = ar.predict(typ='levels', start=val_ind[0], end=val_ind[-1])\n",
    "    true = train_with_ind.iloc[val_ind, -1]\n",
    "    print(np.sqrt(mean_squared_error(true, preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def find_rmse_test(model, test_data=test):\n",
    "    y_hat = model.predict(start=test_data.index[0], end=test_data.index[-1], typ='levels')\n",
    "    return np.sqrt(mean_squared_error(test_data, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(find_rmse_test(baseline))\n",
    "print(find_rmse_test(random_walk_model))\n",
    "print(find_rmse_test(ar_1))\n",
    "print(find_rmse_test(ar_2))\n",
    "print(find_rmse_test(ma_1))\n",
    "print(find_rmse_test(ma_2))\n",
    "print(find_rmse_test(arma_21))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# LEVEL UPS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## ACF and PACF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We have been able to reduce our AIC by chance, adding fairly random p, d, and q terms.\n",
    "\n",
    "But we have tools to help guide us in these decisions: the autocorrelation and partial autocorrelation functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### PACF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In general, a partial correlation is a **conditional correlation**. It is the  amount of correlation between a variable and a lag of itself that is not explained by correlations at all lower-order-lags. If $Y_t$ is correlated with $Y_{t-1}$, and $Y_{t-1}$ is equally correlated with $Y_{t-2}$, then we should also expect to find correlation between $Y_t$ and $Y_{t-2}$. Thus, the correlation at lag 1 \"propagates\" to lag 2 and presumably to higher-order lags. The partial autocorrelation at lag 2 is therefore the difference between the actual correlation at lag 2 and the expected correlation due to the propagation of correlation at lag 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_pacf(train.diff().dropna());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The shaded area of the graph is the confidence interval. When the correlation drops into the shaded area, that means there is no longer statistically significant correlation between lags."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "For an AR process, we run a linear regression on lags according to the order of the AR process. The coefficients calculated factor in the influence of the other variables.   \n",
    "\n",
    "Since the PACF shows the direct effect of previous lags, it helps us choose AR terms.  If there is a significant positive value at a lag, consider adding an AR term according to the number that you see."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Some rules of thumb: \n",
    "\n",
    "    - A sharp drop after lag \"k\" suggests an AR-k model.\n",
    "    - A gradual decline suggests an MA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### ACF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The autocorrelation plot of our time series is simply a version of the correlation plots we used in linear regression.  Our features this time are prior points in the time series, or the **lags**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can calculate a specific covariance ($\\gamma_k$) with:\n",
    "\n",
    "${\\displaystyle \\gamma_k = \\frac 1 n \\sum\\limits_{t=1}^{n-k} (y_t - \\bar{y_t})(y_{t+k}-\\bar{y_{t+k}})}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(train)\n",
    "df.columns = ['lag_0']\n",
    "df['lag_1'] = train.shift()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gamma_1 = sum(((df['lag_0'][1:]-df['lag_0'][1:].mean()) *\\\n",
    "               (df['lag_1'].dropna()-df['lag_1'].dropna().mean())))/(len(df['lag_1'])-1)\n",
    "gamma_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We then compute the Pearson correlation:\n",
    "\n",
    "$\\large\\rho = \\frac {\\operatorname E[(y_1−\\mu_1)(y_2−\\mu_2)]} {\\sigma_{1}\\sigma_{2}} = \\frac {\\operatorname {Cov} (y_1,y_2)} {\\sigma_{1}\\sigma_{2}}$,\n",
    "\n",
    "${\\displaystyle \\rho_k = \\frac {\\sum\\limits_{t=1}^{n-k} (y_t - \\bar{y})(y_{t+k}-\\bar{y})} {\\sum\\limits_{t=1}^{n} (y_t - \\bar{y})^2}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rho = gamma_1/(df.lag_0[1:].std(ddof=0)*df.lag_1.std(ddof=0))\n",
    "rho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(train)\n",
    "df.columns = ['lag_0']\n",
    "df['lag_1'] = train.shift()\n",
    "df['lag_2'] = train.shift(2)\n",
    "df['lag_3'] = train.shift(3)\n",
    "df['lag_4'] = train.shift(4)\n",
    "df['lag_5'] = train.shift(5)\n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "list(df.corr()['lag_0'].index)\n",
    "plt.bar(list(df.corr()['lag_0'].index), list(df.corr()['lag_0']));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Original data\n",
    "\n",
    "plot_acf(train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The above autocorrelation shows that there is correlation between lags up to about 12 weeks back.  \n",
    "\n",
    "When Looking at the ACF graph for the original data, we see a strong persistent correlation with higher order lags. This is evidence that we should take a **first difference** of the data to remove this autocorrelation.\n",
    "\n",
    "This makes sense, since we are trying to capture the effect of recent lags in our ARMA models, and with high correlation between distant lags, our models will not come close to the true process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Generally, we use an ACF to predict MA terms.\n",
    "Moving Average models are using the error terms of the predictions to calculate the next value.  This means that the algorithm does not incorporate the direct effect of the previous value. It models what are sometimes called **impulses** or **shocks** whose effect accounts for the propogation of correlation from one lag to the other. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_acf(train.diff().dropna());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This autocorrelation plot can now be used to get an idea of a potential MA term.  Our differenced series shows negative significant correlation at a lag of 1, which suggests adding 1 MA term. There is also a statistically significant 2nd term, so adding another MA is another possibility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "\n",
    "> If the ACF of the differenced series displays a sharp cutoff and/or the lag-1 autocorrelation is negative--i.e., if the series appears slightly \"overdifferenced\"--then consider adding an MA term to the model. The lag at which the ACF cuts off is the indicated number of MA terms. [Duke](https://people.duke.edu/~rnau/411arim3.htm#signatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Rule of thumb:\n",
    "    \n",
    "  - If the autocorrelation shows negative correlation at the first lag, try adding MA terms.\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "![alt text](images/armaguidelines.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The plots above suggest that we should try a 1st order differenced MA(1) or MA(2) model on our weekly gun offense data.\n",
    "\n",
    "This aligns with our AIC scores from above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The ACF can be used to identify the possible structure of time series data. That can be tricky going forward as there often isn’t a single clear-cut interpretation of a sample autocorrelation function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's plot our training predictions, using an ARIMA model with order (1, 1, 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "aa_model = ARIMA(train, order=(1, 1, 2)).fit()\n",
    "y_hat_train = aa_model.predict(typ='levels')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(y_hat_train)\n",
    "ax.plot(train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Let's zoom in:\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(y_hat_train[50:70])\n",
    "ax.plot(train[50:70])\n",
    "plt.xticks(rotation = 45, ha='right');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "aa_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now that we have chosen our parameters, let's try our model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_hat_test = aa_model.predict(start=test.index[0], end=test.index[-1],typ='levels')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(y_hat_test)\n",
    "plt.xticks(rotation = 45, ha='right');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(y_hat_test)\n",
    "ax.plot(test)\n",
    "plt.xticks(rotation = 45, ha='right');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.sqrt(mean_squared_error(test, y_hat_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Our predictions on the test set certainly leave something to be desired.  \n",
    "\n",
    "Let's take another look at our autocorrelation function of the original series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_acf(ts_weekly);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's increase the lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_acf(ts_weekly, lags=75);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "There seems to be a wave of correlation at around 50 lags.\n",
    "What is going on?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## SARIMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Looks like we may have some other forms of seasonality.  Luckily, we have SARIMA, which stands for Seasonal Auto Regressive Integrated Moving Average.  That is a lot.  The `statsmodels` package is actually called SARIMAX.  The X stands for exogenous, and we are only dealing with endogenous variables, but we can use this class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "A seasonal ARIMA model is classified as an **ARIMA(p,d,q)x(P,D,Q)** model, \n",
    "\n",
    "    **p** = number of autoregressive (AR) terms \n",
    "    **d** = number of differences \n",
    "    **q** = number of moving average (MA) terms\n",
    "     \n",
    "    **P** = number of seasonal autoregressive (SAR) terms \n",
    "    **D** = number of seasonal differences \n",
    "    **Q** = number of seasonal moving average (SMA) terms\n",
    "\n",
    "I.e. P and Q specify the number of seasons to include."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "p = q = range(0, 2)\n",
    "pdq = list(itertools.product(p, [1], q))\n",
    "seasonal_pdq = [(x[0], x[1], x[2], 52) for x in list(itertools.product(p, [1], q))]\n",
    "print('Examples of parameter for SARIMA...')\n",
    "for i in pdq:\n",
    "    for s in seasonal_pdq:\n",
    "        print('SARIMAX: {} x {}'.format(i, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for param in pdq:\n",
    "    for param_seasonal in seasonal_pdq:\n",
    "        try:\n",
    "            mod=SARIMAX(train,\n",
    "                         order=param,\n",
    "                         seasonal_order=param_seasonal,\n",
    "                         enforce_stationarity=False,\n",
    "                         enforce_invertibility=False)\n",
    "            results = mod.fit()\n",
    "            print('ARIMA{}x{} - AIC:{}'.format(param,param_seasonal,results.aic))\n",
    "        except: \n",
    "            print('Oops!')\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's try the third from the bottom, ARIMA(1, 1, 1)x(0, 1, 1, 52)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sari_mod =SARIMAX(train,\n",
    "                  order=(1, 1, 1),\n",
    "                  seasonal_order=(0, 1, 1, 52),\n",
    "                  enforce_stationarity=False,\n",
    "                  enforce_invertibility=False).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for train_ind, val_ind in split.split(train_with_ind):\n",
    "    sarimax = SARIMAX(endog=train_with_ind.iloc[train_ind, -1],\n",
    "                      order=(1, 1, 1),\n",
    "                     seasonal_order=(0, 1, 1, 52),\n",
    "                     enforce_stationarity=False,\n",
    "                     enforce_invertibility=False).fit()\n",
    "    preds = sarimax.predict(typ='levels', start=val_ind[0], end=val_ind[-1])\n",
    "    true = train_with_ind.iloc[val_ind, -1]\n",
    "    print(np.sqrt(mean_squared_error(true, preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_hat_train = sari_mod.predict(typ='levels')\n",
    "y_hat_test = sari_mod.predict(start=test.index[0], end=test.index[-1],typ='levels')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(train, label='train')\n",
    "ax.plot(test, label='test')\n",
    "ax.plot(y_hat_train, label='train_pred')\n",
    "ax.plot(y_hat_test, label='test_pred')\n",
    "\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Let's zoom in on test\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(test, label='true')\n",
    "ax.plot(y_hat_test, label='pred')\n",
    "\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.sqrt(mean_squared_error(test, y_hat_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Lastly, let's predict into the future.\n",
    "\n",
    "To do so, we'll refit to our entire training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sari_mod = SARIMAX(ts_weekly,\n",
    "                  order=(1, 1, 1),\n",
    "                  seasonal_order=(0, 1, 1, 52),\n",
    "                  enforce_stationarity=False,\n",
    "                  enforce_invertibility=False).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "forecast = sari_mod.forecast(steps=52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(ts_weekly, label='so_far')\n",
    "ax.plot(forecast, label='forecast')\n",
    "ax.set_title('Chicago Gun Crime Predictions\\n One Year out')\n",
    "\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "260px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

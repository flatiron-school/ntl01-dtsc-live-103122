{"cells": [{"cell_type": "markdown", "metadata": {"nbgrader": {"grade": false, "grade_id": "cell-a405f9c797c90edb", "locked": true, "schema_version": 3, "solution": false, "task": false}}, "source": ["# TensorFlow Checkpoint\n", "\n", "This assessment covers building and training a `tf.keras` `Sequential` model, then applying regularization.  The dataset comes from a [\"don't overfit\" Kaggle competition](https://www.kaggle.com/c/dont-overfit-ii).  There are 300 features labeled 0-299, and a binary target called \"target\".  There are only 250 records total, meaning this is a very small dataset to be used with a neural network. \n", "\n", "_You can assume that the dataset has already been scaled._"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2020-11-04T16:46:28.793582Z", "start_time": "2020-11-04T16:46:24.326301Z"}, "nbgrader": {"grade": false, "grade_id": "cell-4ab18aba8319e5bb", "locked": true, "schema_version": 3, "solution": false, "task": false}}, "outputs": [], "source": ["# Run this cell without changes\n", "\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "\n", "import numpy as np\n", "import pandas as pd\n", "from sklearn.metrics import accuracy_score\n", "from sklearn.model_selection import train_test_split\n", "\n", "import tensorflow as tf\n", "from tensorflow.keras import Sequential, regularizers\n", "from tensorflow.keras.layers import Dense, Dropout\n", "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier"]}, {"cell_type": "markdown", "metadata": {"nbgrader": {"grade": false, "grade_id": "cell-c7b992c89bbf7019", "locked": true, "schema_version": 3, "solution": false, "task": false}}, "source": ["## 1) Prepare Data for Modeling\n", "\n", "* Using `pandas`, open the file `data.csv` as a DataFrame\n", "* Drop the `\"id\"` column, since this is a unique identifier and not a feature\n", "* Separate the data into `X` (a DataFrame with all columns except `\"target\"`) and `y` (a Series with just the `\"target\"` column)\n", "* The train-test split should work as-is once you create these variables"]}, {"cell_type": "code", "execution_count": null, "metadata": {"nbgrader": {"grade": false, "grade_id": "cell-d01723acad72a02e", "locked": false, "schema_version": 3, "solution": true, "task": false}}, "outputs": [], "source": ["# CodeGrade step1\n", "# Replace None with appropriate code\n", "\n", "# Read in the data\n", "df = None\n", "\n", "# Drop the \"id\" column\n", "None\n", "\n", "# Separate into X and y\n", "X = None\n", "y = None\n", "\n", "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2021)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["assert type(df) == pd.DataFrame\n", "assert type(X) == pd.DataFrame\n", "assert type(y) == pd.Series"]}, {"cell_type": "markdown", "metadata": {"nbgrader": {"grade": false, "grade_id": "cell-2aa2425f887ac9b0", "locked": true, "schema_version": 3, "solution": false, "task": false}}, "source": ["## 2) Instantiate a `Sequential` Model\n", "\n", "In the cell below, create an instance of a `Sequential` model ([documentation here](https://keras.io/guides/sequential_model/)) called `dense_model` with a `name` of `\"dense\"` and otherwise default arguments.\n", "\n", "*In other words, create a model without any layers. We will add layers in a future step.*"]}, {"cell_type": "code", "execution_count": null, "metadata": {"nbgrader": {"grade": false, "grade_id": "cell-6c7980c4f4e802ae", "locked": false, "schema_version": 3, "solution": true, "task": false}}, "outputs": [], "source": ["# CodeGrade step2\n", "# Replace None with appropriate code\n", "dense_model = None\n", "\n", "dense_model.name"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Model should not have any layers yet\n", "assert len(dense_model.layers) == 0"]}, {"cell_type": "markdown", "metadata": {"nbgrader": {"grade": false, "grade_id": "cell-b777879670a57fbf", "locked": true, "schema_version": 3, "solution": false, "task": false}}, "source": ["## 3) Determine Input and Output Shapes\n", "\n", "How many input and output nodes should this model have?\n", "\n", "Feel free to explore the attributes of `X` and `y` to determine this answer, or just to enter numbers based on the problem description above."]}, {"cell_type": "code", "execution_count": null, "metadata": {"nbgrader": {"grade": false, "grade_id": "cell-63ba55e28070fbb7", "locked": false, "schema_version": 3, "solution": true, "task": false}}, "outputs": [], "source": ["# CodeGrade step3\n", "# Replace None with appropriate code\n", "num_input_nodes = None\n", "num_output_nodes = None"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Both values should be integers\n", "assert type(num_input_nodes) == int\n", "assert type(num_output_nodes) == int"]}, {"cell_type": "markdown", "metadata": {"nbgrader": {"grade": false, "grade_id": "cell-1a3c44e684a51352", "locked": true, "schema_version": 3, "solution": false, "task": false}}, "source": ["The code below will use the input and output shapes you specified to add `Dense` layers to the model:"]}, {"cell_type": "code", "execution_count": null, "metadata": {"nbgrader": {"grade": false, "grade_id": "cell-eae488ae8a1e564b", "locked": true, "schema_version": 3, "solution": false, "task": false}}, "outputs": [], "source": ["# Run this cell without changes\n", "\n", "# Add input layer\n", "dense_model.add(Dense(units=64, input_shape=(num_input_nodes,)))\n", "\n", "# Add hidden layers\n", "dense_model.add(Dense(units=64))\n", "dense_model.add(Dense(units=64))\n", "\n", "dense_model.layers"]}, {"cell_type": "markdown", "metadata": {"nbgrader": {"grade": false, "grade_id": "cell-8505e21901e1e252", "locked": true, "schema_version": 3, "solution": false, "task": false}}, "source": ["## 4) Add an Output Layer\n", "\n", "Specify an appropriate activation function ([documentation here](https://keras.io/api/layers/activations/)).\n", "\n", "We'll simplify the problem by specifying that you should use the string identifier for the function, and it should be one of these options:\n", "\n", "* `sigmoid`\n", "* `softmax`\n", "\n", "***Hint:*** is this a binary or a multi-class problem? This should guide your choice of activation function."]}, {"cell_type": "code", "execution_count": null, "metadata": {"nbgrader": {"grade": false, "grade_id": "cell-0aeea3d8ccac319e", "locked": false, "schema_version": 3, "solution": true, "task": false}}, "outputs": [], "source": ["# CodeGrade step4\n", "# Replace None with appropriate code\n", "activation_function = None"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# activation_function should be a string\n", "assert type(activation_function) == str"]}, {"cell_type": "markdown", "metadata": {"nbgrader": {"grade": false, "grade_id": "cell-5c793011c6345392", "locked": true, "schema_version": 3, "solution": false, "task": false}}, "source": ["Now we'll use that information to finalize the model.\n", "\n", "If this code produces an error, consider restarting the kernel and re-running the code above. If it still produces an error, that is an indication that one or more of your answers above is incorrect."]}, {"cell_type": "code", "execution_count": null, "metadata": {"nbgrader": {"grade": false, "grade_id": "cell-e04042f44ccb24bb", "locked": true, "schema_version": 3, "solution": false, "task": false}}, "outputs": [], "source": ["# Run this cell without changes\n", "\n", "# Add output layer\n", "dense_model.add(Dense(units=num_output_nodes, activation=activation_function))\n", "\n", "# Determine appropriate loss function\n", "if num_output_nodes == 1:\n", "    loss = \"binary_crossentropy\"\n", "else:\n", "    loss = \"categorical_crossentropy\"\n", "\n", "# Compile model\n", "dense_model.compile(\n", "    optimizer=\"adam\",\n", "    loss=loss,\n", "    metrics=[\"accuracy\"]\n", ")\n", "\n", "dense_model.summary()"]}, {"cell_type": "code", "execution_count": null, "metadata": {"nbgrader": {"grade": false, "grade_id": "cell-d54efbf306c08d85", "locked": true, "schema_version": 3, "solution": false, "task": false}}, "outputs": [], "source": ["# Run this cell without changes\n", "\n", "# Fit the model to the training data, using a subset of the\n", "# training data as validation data\n", "dense_model_results = dense_model.fit(\n", "    x=X_train,\n", "    y=y_train,\n", "    batch_size=None,\n", "    epochs=20,\n", "    verbose=1,\n", "    validation_split=0.4,\n", "    shuffle=False\n", ")"]}, {"cell_type": "code", "execution_count": null, "metadata": {"nbgrader": {"grade": false, "grade_id": "cell-0639b5c80e98ab40", "locked": true, "schema_version": 3, "solution": false, "task": false}}, "outputs": [], "source": ["# Run this cell without changes\n", "\n", "def plot_loss_and_accuracy(results, final=False):\n", "    \n", "    if final:\n", "        val_label=\"test\"\n", "    else:\n", "        val_label=\"validation\"\n", "\n", "    # Extracting metrics from model fitting\n", "    train_loss = results.history['loss']\n", "    val_loss = results.history['val_loss']\n", "    train_accuracy = results.history['accuracy']\n", "    val_accuracy = results.history['val_accuracy']\n", "\n", "    # Setting up plots\n", "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n", "\n", "    # Plotting loss info\n", "    ax1.set_title(\"Loss\")\n", "    sns.lineplot(x=results.epoch, y=train_loss, ax=ax1, label=\"train\")\n", "    sns.lineplot(x=results.epoch, y=val_loss, ax=ax1, label=val_label)\n", "    ax1.legend()\n", "\n", "    # Plotting accuracy info\n", "    ax2.set_title(\"Accuracy\")\n", "    sns.lineplot(x=results.epoch, y=train_accuracy, ax=ax2, label=\"train\")\n", "    sns.lineplot(x=results.epoch, y=val_accuracy, ax=ax2, label=val_label)\n", "    ax2.legend()\n", "    \n", "plot_loss_and_accuracy(dense_model_results)"]}, {"cell_type": "markdown", "metadata": {"nbgrader": {"grade": false, "grade_id": "cell-3ee94fdb73f6a0bd", "locked": true, "schema_version": 3, "solution": false, "task": false}}, "source": ["## 5) Modify the Code Below to Use Regularization\n", "\n", "\n", "The model appears to be overfitting. To deal with this overfitting, modify the code below to include regularization in the model. You can add L1, L2, both L1 and L2, or dropout regularization.\n", "\n", "Hint: these might be helpful\n", "\n", " - [`Dense` layer documentation](https://keras.io/api/layers/core_layers/dense/)\n", " - [`regularizers` documentation](https://keras.io/regularizers/)\n", " \n", "(`EarlyStopping` is a type of regularization that is not applicable to this problem framing, since it's a callback and not a layer.)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# CodeGrade step5\n", "\n", "def build_model_with_regularization(n_input, n_output, activation, loss):\n", "    \"\"\"\n", "    Creates and compiles a tf.keras Sequential model with two hidden layers\n", "    This time regularization has been added\n", "    \"\"\"\n", "    # create classifier\n", "    classifier = Sequential(name=\"regularized\")\n", "\n", "    # add input layer\n", "    classifier.add(Dense(units=64, input_shape=(n_input,)))\n", "\n", "    # add hidden layers\n", "    \n", "    \n", "\n", "    # add output layer\n", "    classifier.add(Dense(units=n_output, activation=activation))\n", "\n", "    classifier.compile(optimizer='adam', loss=loss, metrics=['accuracy'])\n", "    return classifier\n", "\n", "model_with_regularization = build_model_with_regularization(\n", "    num_input_nodes, num_output_nodes, activation_function, loss\n", ")\n", "model_with_regularization.summary()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Testing function to build model\n", "assert type(model_with_regularization) == Sequential"]}, {"cell_type": "markdown", "metadata": {"nbgrader": {"grade": false, "grade_id": "cell-b13c2342c3515ca5", "locked": true, "schema_version": 3, "solution": false, "task": false}}, "source": ["Now we'll evaluate the new model on the training set as well:"]}, {"cell_type": "code", "execution_count": null, "metadata": {"nbgrader": {"grade": false, "grade_id": "cell-87e75ce032ca5468", "locked": true, "schema_version": 3, "solution": false, "task": false}}, "outputs": [], "source": ["# Run this cell without changes\n", "\n", "# Fit the model to the training data, using a subset of the\n", "# training data as validation data\n", "reg_model_results = model_with_regularization.fit(\n", "    x=X_train,\n", "    y=y_train,\n", "    batch_size=None,\n", "    epochs=20,\n", "    verbose=0,\n", "    validation_split=0.4,\n", "    shuffle=False\n", ")\n", "\n", "plot_loss_and_accuracy(reg_model_results)"]}, {"cell_type": "markdown", "metadata": {"nbgrader": {"grade": false, "grade_id": "cell-cdcc2db42e9c92a2", "locked": true, "schema_version": 3, "solution": false, "task": false}}, "source": ["(Whether or not your regularization made a difference will partially depend on how strong of regularization you applied, as well as some random elements of your current TensorFlow configuration.)\n", "\n", "Now we evaluate both models on the holdout set:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Run this cell without changes\n", "\n", "final_dense_model_results = dense_model.fit(\n", "    x=X_train,\n", "    y=y_train,\n", "    batch_size=None,\n", "    epochs=20,\n", "    verbose=0,\n", "    validation_data=(X_test, y_test),\n", "    shuffle=False\n", ")\n", "\n", "plot_loss_and_accuracy(final_dense_model_results, final=True)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Run this cell without changes\n", "\n", "final_reg_model_results = model_with_regularization.fit(\n", "    x=X_train,\n", "    y=y_train,\n", "    batch_size=None,\n", "    epochs=20,\n", "    verbose=0,\n", "    validation_data=(X_test, y_test),\n", "    shuffle=False\n", ")\n", "\n", "plot_loss_and_accuracy(final_reg_model_results, final=True)"]}], "metadata": {"celltoolbar": "Create Assignment", "kernelspec": {"display_name": "m1a", "language": "python", "name": "m1a"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.13"}, "toc": {"base_numbering": 1, "nav_menu": {}, "number_sections": false, "sideBar": true, "skip_h1_title": true, "title_cell": "Table of Contents", "title_sidebar": "Contents", "toc_cell": false, "toc_position": {}, "toc_section_display": true, "toc_window_display": false}, "varInspector": {"cols": {"lenName": 16, "lenType": 16, "lenVar": 40}, "kernels_config": {"python": {"delete_cmd_postfix": "", "delete_cmd_prefix": "del ", "library": "var_list.py", "varRefreshCmd": "print(var_dic_list())"}, "r": {"delete_cmd_postfix": ") ", "delete_cmd_prefix": "rm(", "library": "var_list.r", "varRefreshCmd": "cat(var_dic_list()) "}}, "types_to_exclude": ["module", "function", "builtin_function_or_method", "instance", "_Feature"], "window_display": false}}, "nbformat": 4, "nbformat_minor": 4}